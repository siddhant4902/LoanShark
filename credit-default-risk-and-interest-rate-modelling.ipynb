{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### In finance, there are several major types of risks that individuals, businesses, and investors need to be aware of and manage. Each type of risk has its own characteristics, causes, and potential consequences. \n\n**The Four major types of risks in finance explained in detail:**\n\n1. **Market Risk:**\n   - **Definition:** Market risk, also known as systematic risk or non-diversifiable risk, is the risk associated with the overall market or a specific market segment. It refers to the potential for losses due to fluctuations in market factors such as interest rates, exchange rates, and stock prices.\n   - **Causes:** Market risk can result from economic events, geopolitical developments, central bank policy changes, and broader market sentiment.\n   - **Consequences:** Market risk can lead to declines in the value of investments and portfolios. It affects all investors to some degree and cannot be eliminated through diversification.\n\n2. **Credit Risk:**\n   - **Definition:** Credit risk, also known as default risk, is the risk that a borrower or issuer of debt securities may fail to meet their financial obligations, such as making interest payments or repaying principal.\n   - **Causes:** Credit risk arises from the financial instability or creditworthiness of borrowers, which can be influenced by economic conditions, business performance, and management decisions.\n   - **Consequences:** Credit risk can result in losses for lenders or investors holding debt securities. It is a primary concern for bondholders and creditors.\n\n3. **Liquidity Risk:**\n   - **Definition:** Liquidity risk is the risk that an asset cannot be bought or sold quickly enough in the market without significantly affecting its price. It pertains to the ease of converting an asset into cash.\n   - **Causes:** Liquidity risk can be caused by a lack of trading activity, market disruptions, or when an asset is illiquid by nature.\n   - **Consequences:** Liquidity risk can lead to difficulties in selling assets when needed, potentially resulting in losses or the inability to meet financial obligations.\n\n4. **Operational Risk:**\n   - **Definition:** Operational risk arises from internal failures, including human errors, system malfunctions, fraud, and inadequate processes or controls within an organization.\n   - **Causes:** Operational risk is often attributed to human actions or system failures. It can also result from external events, such as natural disasters.\n   - **Consequences:** Operational risk can lead to financial losses, damage to reputation, legal issues, and disruptions in business operations.\n   \n   \n### A chart of the other types of financial risks:","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\n\n# Specify the path to the image\nimage_path = \"/kaggle/input/credit-risk/TypesOfFinancialRisk.png\"\n\n# Display the resized image\"\nImage(image_path, width=800, height=800)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-28T16:41:52.406857Z","iopub.execute_input":"2023-09-28T16:41:52.407390Z","iopub.status.idle":"2023-09-28T16:41:52.444437Z","shell.execute_reply.started":"2023-09-28T16:41:52.407349Z","shell.execute_reply":"2023-09-28T16:41:52.443577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In this notebook, my focus would be on: \n\n- **credit risk**\n\n- **how are loan borrowers assessed and graded based on their credit history**\n\n- **creating a model to help profile a new borrower**\n\n- **predict an appropriate interest rate for them, based on their history**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/credit-risk/loan.csv', low_memory=False)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:51:58.590008Z","iopub.execute_input":"2023-09-28T16:51:58.590391Z","iopub.status.idle":"2023-09-28T16:52:15.564970Z","shell.execute_reply.started":"2023-09-28T16:51:58.590358Z","shell.execute_reply":"2023-09-28T16:52:15.563687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"id":"GebKnL9pzb1g","outputId":"c7fceabc-9ed6-4060-bdd8-6777b7a24157","execution":{"iopub.status.busy":"2023-09-28T16:52:15.567162Z","iopub.execute_input":"2023-09-28T16:52:15.567884Z","iopub.status.idle":"2023-09-28T16:52:17.051122Z","shell.execute_reply.started":"2023-09-28T16:52:15.567843Z","shell.execute_reply":"2023-09-28T16:52:17.050019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False)","metadata":{"id":"bz2PqmHszb1i","outputId":"edf87902-a4ce-405c-f975-d9f2da0b4e56","execution":{"iopub.status.busy":"2023-09-28T16:52:17.052507Z","iopub.execute_input":"2023-09-28T16:52:17.052874Z","iopub.status.idle":"2023-09-28T16:52:18.801436Z","shell.execute_reply.started":"2023-09-28T16:52:17.052839Z","shell.execute_reply":"2023-09-28T16:52:18.800374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes.value_counts()","metadata":{"id":"lk-sFBaRzb1j","outputId":"80cea291-f6dc-44d1-b78e-a7ab1c17a686","execution":{"iopub.status.busy":"2023-09-28T16:52:18.803799Z","iopub.execute_input":"2023-09-28T16:52:18.804225Z","iopub.status.idle":"2023-09-28T16:52:18.812169Z","shell.execute_reply.started":"2023-09-28T16:52:18.804193Z","shell.execute_reply":"2023-09-28T16:52:18.811097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define the desired order for the 'grade' variable (alphabetical sorting)\ngrade_order = sorted(data['grade'].unique())\n\n# Define a custom color palette with colors in increasing order\ncustom_palette = sns.color_palette(\"coolwarm\", len(grade_order))\n\nsample_size = 1000  # Adjust this to your desired sample size\nsampled_data = data.sample(sample_size)\n\n# Create a scatter plot\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='loan_amnt', y='int_rate', hue='grade', hue_order=grade_order, \n                data=sampled_data, palette=custom_palette)\n\n# Add labels and title\nplt.xlabel('Loan Amount')\nplt.ylabel('Interest Rate')\nplt.title('Interest Rates vs Loan Amount')\n\n# Show legend and customize the legend title\nplt.legend(title='Grade', loc='upper right')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:52:18.813752Z","iopub.execute_input":"2023-09-28T16:52:18.814175Z","iopub.status.idle":"2023-09-28T16:52:19.416159Z","shell.execute_reply.started":"2023-09-28T16:52:18.814140Z","shell.execute_reply":"2023-09-28T16:52:19.415261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**You can observe patterns in the interest rate segmentation, almost seems like clusters of them.**\n\n- As the interest rate increases for each category of loan amount lended, the grade decreases.\n\n- Borrowers with a lower grade or a \"Credit Rating or Score\" are assigned a higher interest rate, as lending money to borrowers with lower credit score is termed as risky by the lender, thus a premium is charged as a hedge against the risk the lender undertakes. Lending institutions operate to maximize their profits while managing risks. They use credit scoring models and other underwriting criteria to assess the credit-worthiness of borrowers. The interest rate assigned to a borrower is a reflection of the lender's perception of risk against him. Lenders seek to strike a balance between offering competitive rates to attract borrowers and ensuring that the interest rates cover potential losses due to defaults.\n\n- Borrowers can influence their interest rates by improving their credit profiles. This may involve maintaining a good payment history, reducing outstanding debt, and managing their credit responsibly. By doing so, borrowers can qualify for loans with lower interest rates and better terms.\n\n- It's essential to note that interest rates can also be influenced by regulatory changes and broader economic conditions. Government policies, market interest rates, and lender competition can impact the rates offered to borrowers.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Change in interest rates with changes in grades\nplt.figure(figsize=(12, 6))\nsns.pointplot(x='sub_grade', y='int_rate', data=data, order=sorted(data['sub_grade'].unique()))\nplt.title(\"Interest Rate vs Grades\")\nplt.xlabel(\"Subgrade\")\nplt.ylabel(\"Interest Rate\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:03:32.352990Z","iopub.execute_input":"2023-09-28T17:03:32.353368Z","iopub.status.idle":"2023-09-28T17:03:42.571641Z","shell.execute_reply.started":"2023-09-28T17:03:32.353338Z","shell.execute_reply":"2023-09-28T17:03:42.570686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a histogram plot of interest rates grouped by grades\nplt.figure(figsize=(10, 6))\n\n# Define the desired order for the 'grade' variable (alphabetical sorting)\ngrade_order = sorted(data['grade'].unique())\n\n# Define a custom color palette with colors in increasing order\ncustom_palette = sns.color_palette(\"coolwarm\", len(grade_order))\n\nsns.histplot(data=data, x='int_rate', hue='grade',hue_order=grade_order, bins=30, kde=True)\nplt.title('Interest Rate Distribution by Grades')\nplt.xlabel('Interest Rate')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:04:46.553047Z","iopub.execute_input":"2023-09-28T17:04:46.553437Z","iopub.status.idle":"2023-09-28T17:04:53.290360Z","shell.execute_reply.started":"2023-09-28T17:04:46.553404Z","shell.execute_reply":"2023-09-28T17:04:53.289446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each grade\ngrade_counts = data['grade'].value_counts()\n\n# Create a bar plot\nplt.figure(figsize=(8, 6))\ngrade_counts.plot(kind='bar')\nplt.title('Number of Loans per Grade')\nplt.xlabel('Grade')\nplt.ylabel('Number of Loans')\nplt.xticks(rotation=0)  # To make sure the grade labels are not rotated\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:25:48.163727Z","iopub.execute_input":"2023-09-28T16:25:48.164717Z","iopub.status.idle":"2023-09-28T16:25:48.523272Z","shell.execute_reply.started":"2023-09-28T16:25:48.164682Z","shell.execute_reply":"2023-09-28T16:25:48.522366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the data by subgrade and count the number of occurrences\nsubgrade_counts = data['sub_grade'].value_counts()\n\n# Create a DataFrame from the counts\nsubgrade_counts_df = pd.DataFrame({'Subgrade': subgrade_counts.index, 'Count': subgrade_counts.values})\n\n# Plot the stacked bar chart\nplt.figure(figsize=(12, 6))\nplt.bar(subgrade_counts_df['Subgrade'], subgrade_counts_df['Count'])\nplt.xlabel('Subgrade')\nplt.ylabel('Count')\nplt.title('Number of Loans by Subgrade')\nplt.xticks(rotation=45)  # Rotate x-axis labels for better readability\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:25:48.524614Z","iopub.execute_input":"2023-09-28T16:25:48.525213Z","iopub.status.idle":"2023-09-28T16:25:49.059301Z","shell.execute_reply.started":"2023-09-28T16:25:48.525178Z","shell.execute_reply":"2023-09-28T16:25:49.058367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of loan amounts\nplt.figure(figsize=(10, 6))\nsns.histplot(data['loan_amnt'], bins=30, kde=True)\nplt.title('Loan Amount Distribution')\nplt.xlabel('Loan Amount')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:25:49.060777Z","iopub.execute_input":"2023-09-28T16:25:49.061804Z","iopub.status.idle":"2023-09-28T16:25:53.204185Z","shell.execute_reply.started":"2023-09-28T16:25:49.061769Z","shell.execute_reply":"2023-09-28T16:25:53.203276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of interest rates\nplt.figure(figsize=(10, 6))\nsns.histplot(data['int_rate'], bins=30, kde=True)\nplt.title('Interest Rate Distribution')\nplt.xlabel('Interest Rate')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:25:53.208822Z","iopub.execute_input":"2023-09-28T16:25:53.209108Z","iopub.status.idle":"2023-09-28T16:25:57.559217Z","shell.execute_reply.started":"2023-09-28T16:25:53.209083Z","shell.execute_reply":"2023-09-28T16:25:57.558338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the count of different loan terms\nplt.figure(figsize=(8, 5))\nsns.countplot(x='term', data=data)\nplt.title('Count of Loan Terms')\nplt.xlabel('Term')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:25:57.560792Z","iopub.execute_input":"2023-09-28T16:25:57.561908Z","iopub.status.idle":"2023-09-28T16:25:58.606237Z","shell.execute_reply.started":"2023-09-28T16:25:57.561872Z","shell.execute_reply":"2023-09-28T16:25:58.605330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With a suitable understanding of the dataset from the above exploration, we can go ahead with pre-processing data for the model.","metadata":{}},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{"id":"IAQwq08qzb1j"}},{"cell_type":"code","source":"# Set the threshold for null values (80% in this case), higher than it will get dropped\nthreshold = 0.80\n\n# Calculate the number of null values in each column\nnull_counts = data.isnull().sum()\nnull_percentages = (null_counts / len(data)) * 100\n\n# Identify columns with null percentages greater than or equal to the threshold\ncolumns_to_drop = null_percentages[null_percentages >= threshold].index\ndata = data.drop(columns=columns_to_drop)\n\ndata.shape","metadata":{"id":"X2td6N0xzb1l","execution":{"iopub.status.busy":"2023-09-28T16:44:46.517493Z","iopub.execute_input":"2023-09-28T16:44:46.518547Z","iopub.status.idle":"2023-09-28T16:44:48.421632Z","shell.execute_reply.started":"2023-09-28T16:44:46.518500Z","shell.execute_reply":"2023-09-28T16:44:48.420405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The size decreased from (887379,74) to x46, thus 28 high null columns were dropped**","metadata":{}},{"cell_type":"code","source":"# Separating a table which containts target features for the model\n\ntarget_columns = ['id', 'grade', 'sub_grade', 'int_rate']\ntarget = data[target_columns].copy()\n\n# Remove the specified columns from the original DataFrame 'data'\ndata.drop(['grade', 'sub_grade'], axis=1, inplace=True)\n\ntarget","metadata":{"id":"ejFLWSuizb1m","outputId":"865e58eb-0aab-477d-f9d8-9701908c2fb3","execution":{"iopub.status.busy":"2023-09-28T16:48:10.642222Z","iopub.execute_input":"2023-09-28T16:48:10.642629Z","iopub.status.idle":"2023-09-28T16:48:10.945155Z","shell.execute_reply.started":"2023-09-28T16:48:10.642597Z","shell.execute_reply":"2023-09-28T16:48:10.943979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for any null values\ntarget.isna().sum()","metadata":{"id":"a6hPmtegzb1v","outputId":"e6be65d8-8d69-4e42-d8be-8d73685109d8","execution":{"iopub.status.busy":"2023-09-28T16:48:11.091279Z","iopub.execute_input":"2023-09-28T16:48:11.092973Z","iopub.status.idle":"2023-09-28T16:48:11.259096Z","shell.execute_reply.started":"2023-09-28T16:48:11.092889Z","shell.execute_reply":"2023-09-28T16:48:11.257521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text pre-processing","metadata":{"id":"QxSOfqVfzb1w"}},{"cell_type":"code","source":"object_columns = data.select_dtypes(include=['object']).columns\n\nfor column in object_columns:\n    print(column)","metadata":{"id":"CF0M2UIczb1x","outputId":"55132a21-c713-4fb8-e827-899100d2d7d7","execution":{"iopub.status.busy":"2023-09-28T16:48:11.260656Z","iopub.execute_input":"2023-09-28T16:48:11.260943Z","iopub.status.idle":"2023-09-28T16:48:11.370179Z","shell.execute_reply.started":"2023-09-28T16:48:11.260918Z","shell.execute_reply":"2023-09-28T16:48:11.369117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Identifying the differnt values in categorical columns\n\nfor column in data[object_columns].columns:\n    unique_values = data[column].value_counts()\n    print(f\"\\nColumn: {column}\")\n    print(unique_values)","metadata":{"id":"MQk3Lyukzb1y","outputId":"b9f0c4da-8dca-4743-e9b9-362b8f025975","execution":{"iopub.status.busy":"2023-09-28T16:48:11.371579Z","iopub.execute_input":"2023-09-28T16:48:11.372400Z","iopub.status.idle":"2023-09-28T16:48:13.747470Z","shell.execute_reply.started":"2023-09-28T16:48:11.372366Z","shell.execute_reply":"2023-09-28T16:48:13.746492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping some useless columns, which won't contribute to the model\n\ndata.drop(['url', 'policy_code', 'member_id'], axis=1, inplace=True)","metadata":{"id":"R_NNsj0mzb1z","execution":{"iopub.status.busy":"2023-09-28T16:48:13.750017Z","iopub.execute_input":"2023-09-28T16:48:13.750648Z","iopub.status.idle":"2023-09-28T16:48:13.956142Z","shell.execute_reply.started":"2023-09-28T16:48:13.750613Z","shell.execute_reply":"2023-09-28T16:48:13.954858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorical encoding for selective features\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\ncolumns = ['home_ownership', 'verification_status', 'initial_list_status', 'application_type', 'pymnt_plan']\nfor col in columns:\n    data[col] = le.fit_transform(data[col])","metadata":{"id":"xUFPZ8L6zb1z","execution":{"iopub.status.busy":"2023-09-28T16:48:13.957613Z","iopub.execute_input":"2023-09-28T16:48:13.957961Z","iopub.status.idle":"2023-09-28T16:48:15.135169Z","shell.execute_reply.started":"2023-09-28T16:48:13.957929Z","shell.execute_reply":"2023-09-28T16:48:15.134176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separating a table containing features which require text pre-processing\ntext_columns = ['id', 'issue_d', 'earliest_cr_line', 'last_credit_pull_d', 'term', 'title', 'purpose', 'addr_state', 'zip_code', 'loan_status']\n\n# creating a copy here, so that you can run the below cell to get text df back,\n# if you mess up on some processing down below\ndata_c = data.copy()\n\n# Remove the specified columns, except for 'id', from the original DataFrame 'data'\ndata.drop(columns=[col for col in text_columns if col != 'id'], inplace=True)","metadata":{"id":"f8rf27Smzb1z","execution":{"iopub.status.busy":"2023-09-28T16:48:15.136785Z","iopub.execute_input":"2023-09-28T16:48:15.137155Z","iopub.status.idle":"2023-09-28T16:48:15.699874Z","shell.execute_reply.started":"2023-09-28T16:48:15.137121Z","shell.execute_reply":"2023-09-28T16:48:15.698876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new DataFrame 'text' containing the specified columns, \n# including 'id', as it would help in merging back later\ntext = data_c[text_columns].copy()\n\ntext","metadata":{"id":"GvEJouFazb10","outputId":"628e19b2-3105-4622-939c-d3a861e138e3","execution":{"iopub.status.busy":"2023-09-28T16:48:15.701512Z","iopub.execute_input":"2023-09-28T16:48:15.701884Z","iopub.status.idle":"2023-09-28T16:48:15.901657Z","shell.execute_reply.started":"2023-09-28T16:48:15.701849Z","shell.execute_reply":"2023-09-28T16:48:15.900527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text.to_csv('loan/loan_text.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:48:15.903287Z","iopub.execute_input":"2023-09-28T16:48:15.903661Z","iopub.status.idle":"2023-09-28T16:48:15.909060Z","shell.execute_reply.started":"2023-09-28T16:48:15.903628Z","shell.execute_reply":"2023-09-28T16:48:15.908166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the counts for each loan status\nloan_status_counts = text['loan_status'].value_counts().reset_index()\nloan_status_counts.columns = ['Loan Status', 'Count']\n\n# Create the horizontal bar graph\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Count', y='Loan Status', data=loan_status_counts)\nplt.title('Loan Status Distribution')\nplt.xlabel('Count')\nplt.ylabel('Loan Status')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:48:15.913426Z","iopub.execute_input":"2023-09-28T16:48:15.914574Z","iopub.status.idle":"2023-09-28T16:48:16.347317Z","shell.execute_reply.started":"2023-09-28T16:48:15.914540Z","shell.execute_reply":"2023-09-28T16:48:16.346372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explaining the Loan Status'\nThe loan status' are basically of 4 types, with each having sub-divisions\n\n1. **Active Loans**\n* Recently issued loans (<6 months)\n* Currently active, i.e. under their tenure\n\n\n2. **Fully Paid Loans**\n* Does not meet the credit policy. Status:Fully Paid\n* Fully Paid - All outstanding payments are done and loan is closed.\n\n\n3. **Defaulted Loans**\n* In Grace Period - 1-15 days have passed since the due date\n* Late (16-30 days) - 16-30 days have passed since due date\n* Late (31-120 days) - 31-120 days have passed since due date\n\n\n4. **Loans with Late Payments**\n* Default - The borrower is not able to make outstanding payments for an extended period of time\n* Charged Off - A charge-off usually occurs when the creditor has deemed an outstanding debt is uncollectible\n* Does not meet the credit policy. Status:Charged Off","metadata":{"id":"KCqe0gEYzb14"}},{"cell_type":"code","source":"# Define a custom encoding dictionary\n# assign weights to categories based on what impact they should have\ncustom_encoding = {\n    'Fully Paid': 10,\n    'Does not meet the credit policy. Status:Fully Paid': 8,\n    'Current': 4,\n    'Issued': 2,\n    'In Grace Period': 0,\n    'Late (16-30 days)': -2,\n    'Late (31-120 days)': -5,\n    'Charged Off': -7,\n    'Does not meet the credit policy. Status:Charged Off': -9,\n    'Default': -10\n}\n\n# Apply the custom encoding\ntext['loan_status'] = text['loan_status'].map(custom_encoding)","metadata":{"id":"XxxpJT3fzb16","execution":{"iopub.status.busy":"2023-09-28T16:48:16.348775Z","iopub.execute_input":"2023-09-28T16:48:16.349102Z","iopub.status.idle":"2023-09-28T16:48:16.441201Z","shell.execute_reply.started":"2023-09-28T16:48:16.349069Z","shell.execute_reply":"2023-09-28T16:48:16.440186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\n# Specify the path to the image\nimage_path = \"/kaggle/input/credit-risk/loan-default_633ad27865f83.jpg\"\n\n# Display the resized image\"\nImage(image_path, width=800, height=800)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-28T16:48:16.443350Z","iopub.execute_input":"2023-09-28T16:48:16.444163Z","iopub.status.idle":"2023-09-28T16:48:16.490063Z","shell.execute_reply.started":"2023-09-28T16:48:16.444129Z","shell.execute_reply":"2023-09-28T16:48:16.489069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Even one missed payment can damage your credit score!\n\n**If a period of 120 days has passed since the default notice, the creditor will send a letter claiming the total amount payable.**\n\n1. Secured loans\n\nIn the case of secured loans like loans against property, home loans and car loans, the legal rights of the property or the car is handed over to the lender in repeated cases of default. If assets like gold, shares/ other investments and insurance are pledged, the lender takes possession of these assets to sell them off at market value and recover their loss. Here, the lender has the right to sell the asset to recover their funds when you have too many defaults. However, before they do so, the financial institution is obligated to notify the borrower to pay off their debt within a specified time limit.\n\n2. Unsecured loans: If you don't pledge any asset or provide any guarantor, the loan is considered unsecured. Defaulting on such loans could lead to the following\n* An increased Interest rate: If you haven't paid your EMIs, the lender will increase the interest rate and/ or levy additional fees and charges on your loan.\n* A lower credit score: An EMI default would lead to the borrower's credit score lowered, which affects his future ability to take debt.\n* Collection agencies: Some lenders turn to collection agencies to get back their money. These agencies could call you. write you letters or make a house visit.\n* A lawsuit by the lender: Some lenders who don't receive their money sue the defaulting borrowers. This could mean clearing off the outstanding and paying for the legal fees and charges for the borrower.\n\n3. Student loans\n\nStudent loans are often considered high risk in terms of default due to the nature of the loan. Students usually struggle to meet their payment right out of college, which ultimately leads to increased interest amounts and a bad credit score in the long run, which can hamper their future credit capability.","metadata":{"id":"sdcp0Pl4zb18"}},{"cell_type":"markdown","source":"\nIf you do default on a loan, don't worry. You can bring yourself out of that situation by taking the following steps:\n\n1. Don't panic: Defaulting a loan payment can cause stress and worry. Begin with calmly figuring out your expenditure and understanding how you were unable to make the payment.\n\n2. Communicate with the lender: Explain the reason for your loan default and work out a solution that benefits both of you. Some institutions are flexible with their policy terms, which can come in handy when negotiating your repayment plan.\n\n3. Consider refinancing: Refinancing gives you the ability to reduce your monthly EMI amount. However, most financial institutions will only consider individuals with good credit scores for refinancing.","metadata":{"id":"y5_XcF7uzb18"}},{"cell_type":"code","source":"from IPython.display import Image\n\n# Specify the path to the image\nimage_path = \"/kaggle/input/credit-risk/us-regions-map.jpg\"\n\n# Display the resized image\"\nImage(image_path, width=800, height=800)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-28T16:48:16.491306Z","iopub.execute_input":"2023-09-28T16:48:16.491702Z","iopub.status.idle":"2023-09-28T16:48:16.510166Z","shell.execute_reply.started":"2023-09-28T16:48:16.491672Z","shell.execute_reply":"2023-09-28T16:48:16.509401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature engineering the borrower's location\n\nThe first three digits of a U.S. ZIP code represent a sectional center facility (SCF). An SCF is a central mail processing facility that serves as a hub for mail distribution within a specific geographic region. These three digits help route mail more efficiently within the United States.\n\nThe first digit of the ZIP code represents a group of U.S. states, and the second and third digits represent a region within that group (or perhaps a large city). Together, these first three digits narrow down the destination area for incoming mail. The remaining two digits in a ZIP code provide even more precise location information.\n\nFor example, in the ZIP code \"90210,\" the first digit \"9\" represents a group of western U.S. states, and the \"02\" represents a particular area within that region, which happens to correspond to Beverly Hills, California. The final \"10\" provides additional specificity within Beverly Hills.\n\nIn this example, we only have values for the first three digits. However, since we have the state names, we can create a new first digit, by encoding the region in which person might live in, followed by the extracted three digit zip code. \n\nThe US is divided up into five regions:\n- Northeast\n- West\n- Midwest\n- Southwest\n- Southeast","metadata":{"id":"bIPKTWwDzb19"}},{"cell_type":"code","source":"# Define the mapping of state abbreviations to regions\n\nstate_to_region = {\n    'AL': 'Southeast',\n    'AK': 'West',\n    'AZ': 'Southwest',\n    'AR': 'Southeast',\n    'CA': 'West',\n    'CO': 'West',\n    'CT': 'Northeast',\n    'DE': 'Northeast',\n    'DC': 'Northeast',\n    'FL': 'Southeast',\n    'GA': 'Southeast',\n    'HI': 'West',\n    'ID': 'West',\n    'IL': 'Midwest',\n    'IN': 'Midwest',\n    'IA': 'Midwest',\n    'KS': 'Midwest',\n    'KY': 'Southeast',\n    'LA': 'Southeast',\n    'ME': 'Northeast',\n    'MD': 'Northeast',\n    'MA': 'Northeast',\n    'MI': 'Midwest',\n    'MN': 'Midwest',\n    'MS': 'Southeast',\n    'MO': 'Midwest',\n    'MT': 'West',\n    'NE': 'Midwest',\n    'NV': 'West',\n    'NH': 'Northeast',\n    'NJ': 'Northeast',\n    'NM': 'Southwest',\n    'NY': 'Northeast',\n    'NC': 'Southeast',\n    'ND': 'Midwest',\n    'OH': 'Midwest',\n    'OK': 'Southwest',\n    'OR': 'West',\n    'PA': 'Northeast',\n    'RI': 'Northeast',\n    'SC': 'Southeast',\n    'SD': 'Midwest',\n    'TN': 'Southeast',\n    'TX': 'Southwest',\n    'UT': 'West',\n    'VT': 'Northeast',\n    'VA': 'Southeast',\n    'WA': 'West',\n    'WV': 'Southeast',\n    'WI': 'Midwest',\n    'WY': 'West'\n}\n\n# Clean and map the state abbreviations\ntext['addr_state'] = text['addr_state'].str.strip()\n\n# Create a new column 'region' based on the mapping\ntext['region'] = text['addr_state'].map(state_to_region)","metadata":{"id":"pwAygUk3zb1-","execution":{"iopub.status.busy":"2023-09-28T16:48:16.511418Z","iopub.execute_input":"2023-09-28T16:48:16.512304Z","iopub.status.idle":"2023-09-28T16:48:16.950513Z","shell.execute_reply.started":"2023-09-28T16:48:16.512263Z","shell.execute_reply":"2023-09-28T16:48:16.949497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.countplot(x='region', data=text)\nplt.title('Borrower Locations by State')\nplt.xlabel('State')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:48:16.952100Z","iopub.execute_input":"2023-09-28T16:48:16.952499Z","iopub.status.idle":"2023-09-28T16:48:18.066306Z","shell.execute_reply.started":"2023-09-28T16:48:16.952448Z","shell.execute_reply":"2023-09-28T16:48:18.065392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text.drop(['addr_state'], axis=1, inplace=True)\n\ntext['region'] = le.fit_transform(text['region'])\n\n# Merge 'zip_code' and 'region' and convert to integer\ntext['location'] = text['region'].astype(str) + text['zip_code'].astype(str)\n\n# Extract the first four characters from 'location'\ntext['location'] = text['location'].str[:4]\ntext['location'] = text['location'].astype(int)\n\ntext.drop(['region', 'zip_code'], axis=1, inplace=True)","metadata":{"id":"5gtuj4tizb1-","execution":{"iopub.status.busy":"2023-09-28T16:48:18.067852Z","iopub.execute_input":"2023-09-28T16:48:18.068851Z","iopub.status.idle":"2023-09-28T16:48:19.686190Z","shell.execute_reply.started":"2023-09-28T16:48:18.068815Z","shell.execute_reply":"2023-09-28T16:48:19.685149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling the Date Columns\n\nThe columns \"issue_d,\" \"earliest_cr_line,\" and \"last_credit_pull_d\" in a loan dataset represent dates related to a borrower's credit history and the loan issuance.\n\n<br> 1. **\"issue_d\" (Issue Date):**\n   - represents the date when the loan was issued or originated.\n   - Lenders use this date to track when the borrower received the loan.\n\n\n<br> 2. **\"earliest_cr_line\" (Earliest Credit Line):**\n   - represents the date when the borrower opened their earliest known credit account.\n   - It is a crucial date in assessing a borrower's credit history and length of credit.\n   - Lenders consider the length of credit history when evaluating creditworthiness.\n\n\n<br> 3. **\"last_credit_pull_d\" (Last Credit Pull Date):**\n   - represents the date when the most recent inquiry or update was made to the borrower's credit report by a lender or financial institution.\n   - It indicates the date when the lender last checked the borrower's credit information.\n   - Lenders may use this date to ensure the borrower's creditworthiness has not changed significantly since the loan application.","metadata":{"id":"A1wTz37bzb1_"}},{"cell_type":"code","source":"import numpy as np\n\n# Fill missing values in 'earliest_cr_line' and 'last_credit_pull_d' with empty strings\nna_text_cols = ['earliest_cr_line', 'last_credit_pull_d']\n\nfor col in na_text_cols:\n    text[col].fillna(\"2016-01-01\", inplace=True)\n\n# Convert the date strings to datetime objects\ntext['issue_d'] = pd.to_datetime(text['issue_d'])\ntext['earliest_cr_line'] = pd.to_datetime(text['earliest_cr_line'])\ntext['last_credit_pull_d'] = pd.to_datetime(text['last_credit_pull_d'])\n\n# feature engineering the datetime columns\ntext['issue_d'] = ((pd.to_datetime(\"2016-01-01\") - text['issue_d']) / np.timedelta64(1, 'M')) / 12\ntext['earliest_cr_line'] = ((pd.to_datetime(\"2016-01-01\") - text['earliest_cr_line']) / np.timedelta64(1, 'M')) / 12\ntext['last_credit_pull_d'] = ((pd.to_datetime(\"2016-01-01\") - text['last_credit_pull_d']) / np.timedelta64(1, 'M')) / 12","metadata":{"id":"q2COLHcRzb1_","execution":{"iopub.status.busy":"2023-09-28T16:48:19.687923Z","iopub.execute_input":"2023-09-28T16:48:19.688334Z","iopub.status.idle":"2023-09-28T16:48:20.486079Z","shell.execute_reply.started":"2023-09-28T16:48:19.688299Z","shell.execute_reply":"2023-09-28T16:48:20.484519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split 'term' column on space and keep only the first term\ntext['term'] = text['term'].str.split(' ').str[1]\n\n# # Divide the 'term' values by 12 to get a yearly term\ntext['term'] = text['term'].astype(int) / 12","metadata":{"id":"fBYNwMJczb1_","execution":{"iopub.status.busy":"2023-09-28T16:48:20.487404Z","iopub.execute_input":"2023-09-28T16:48:20.487988Z","iopub.status.idle":"2023-09-28T16:48:23.892971Z","shell.execute_reply.started":"2023-09-28T16:48:20.487954Z","shell.execute_reply":"2023-09-28T16:48:23.891938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filling up na with value in purpose, so that the merged column doesn't throw NA values\ntext['purpose'] = text['purpose'].str.replace('_', ' ')\n\ntext['purpose'] = le.fit_transform(text['purpose'])\n\ntext.drop(['title'], axis=1, inplace=True)","metadata":{"id":"p1vO3-lfzb1_","execution":{"iopub.status.busy":"2023-09-28T16:48:23.894494Z","iopub.execute_input":"2023-09-28T16:48:23.894836Z","iopub.status.idle":"2023-09-28T16:48:24.721038Z","shell.execute_reply.started":"2023-09-28T16:48:23.894802Z","shell.execute_reply":"2023-09-28T16:48:24.720015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text.to_csv('loan/text_cleaned.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:48:24.722320Z","iopub.execute_input":"2023-09-28T16:48:24.723137Z","iopub.status.idle":"2023-09-28T16:48:24.728100Z","shell.execute_reply.started":"2023-09-28T16:48:24.723104Z","shell.execute_reply":"2023-09-28T16:48:24.726936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, merging the divided columns to move ahead with further model building","metadata":{"id":"2vMFBqVwzb2A"}},{"cell_type":"code","source":"data = pd.merge(data, text, on='id', how='outer')","metadata":{"id":"8SMNV0jSzb2A","execution":{"iopub.status.busy":"2023-09-28T16:48:24.729412Z","iopub.execute_input":"2023-09-28T16:48:24.729826Z","iopub.status.idle":"2023-09-28T16:48:25.041117Z","shell.execute_reply.started":"2023-09-28T16:48:24.729793Z","shell.execute_reply":"2023-09-28T16:48:25.040041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:48:25.045355Z","iopub.execute_input":"2023-09-28T16:48:25.045668Z","iopub.status.idle":"2023-09-28T16:48:25.313469Z","shell.execute_reply.started":"2023-09-28T16:48:25.045641Z","shell.execute_reply":"2023-09-28T16:48:25.312434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling rest of the missing values","metadata":{"id":"307NjEO0zb2A"}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\n# Initialize the KNNImputer with the number of neighbors (k)\nknn_imputer = KNNImputer(n_neighbors=50)\n\n# Perform KNN imputation on the DataFrame\ndata_imputed = knn_imputer.fit_transform(data)\n\n# Convert the result back to a DataFrame\ndata = pd.DataFrame(data_imputed, columns=data.columns)\n\ndata","metadata":{"id":"4aFr2KfIzb2B","outputId":"1d2e0550-bff8-4a44-acbf-35c352a7f6bf","execution":{"iopub.status.busy":"2023-09-28T16:48:25.316815Z","iopub.execute_input":"2023-09-28T16:48:25.317117Z","iopub.status.idle":"2023-09-28T16:50:55.752070Z","shell.execute_reply.started":"2023-09-28T16:48:25.317091Z","shell.execute_reply":"2023-09-28T16:50:55.750922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(25,10))\ncor = data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:50:55.753673Z","iopub.execute_input":"2023-09-28T16:50:55.754041Z","iopub.status.idle":"2023-09-28T16:51:03.798203Z","shell.execute_reply.started":"2023-09-28T16:50:55.754006Z","shell.execute_reply":"2023-09-28T16:51:03.797373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data.to_csv('loan/loan_cleaned.csv', index=False)","metadata":{"id":"M_zylQqBzb2C","execution":{"iopub.status.busy":"2023-09-28T16:28:50.822679Z","iopub.execute_input":"2023-09-28T16:28:50.823018Z","iopub.status.idle":"2023-09-28T16:28:50.827402Z","shell.execute_reply.started":"2023-09-28T16:28:50.822987Z","shell.execute_reply":"2023-09-28T16:28:50.826586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Credit Risk Model","metadata":{"id":"rYGpi-E_zb2C"}},{"cell_type":"code","source":"# creating a copy as a fail safe in case of any errors, and a restart is required\ndata_m = data.copy()","metadata":{"id":"KDlfU0OTzb2C","execution":{"iopub.status.busy":"2023-09-28T16:28:50.828814Z","iopub.execute_input":"2023-09-28T16:28:50.829823Z","iopub.status.idle":"2023-09-28T16:28:50.941612Z","shell.execute_reply.started":"2023-09-28T16:28:50.829791Z","shell.execute_reply":"2023-09-28T16:28:50.940524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_m.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:28:50.943300Z","iopub.execute_input":"2023-09-28T16:28:50.943688Z","iopub.status.idle":"2023-09-28T16:28:51.028848Z","shell.execute_reply.started":"2023-09-28T16:28:50.943653Z","shell.execute_reply":"2023-09-28T16:28:51.027758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\n# Step 1: Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data_m)","metadata":{"id":"isqEP2bmzb2C","execution":{"iopub.status.busy":"2023-09-28T16:28:51.030219Z","iopub.execute_input":"2023-09-28T16:28:51.031193Z","iopub.status.idle":"2023-09-28T16:28:51.445850Z","shell.execute_reply.started":"2023-09-28T16:28:51.031156Z","shell.execute_reply":"2023-09-28T16:28:51.444795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=0.90)  # Choose the explained variance threshold\nreduced_data = pca.fit_transform(scaled_data)","metadata":{"id":"4ooaK-0ozb2D","execution":{"iopub.status.busy":"2023-09-28T16:28:51.447504Z","iopub.execute_input":"2023-09-28T16:28:51.447850Z","iopub.status.idle":"2023-09-28T16:28:54.258367Z","shell.execute_reply.started":"2023-09-28T16:28:51.447816Z","shell.execute_reply":"2023-09-28T16:28:54.257375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:28:54.260058Z","iopub.execute_input":"2023-09-28T16:28:54.260414Z","iopub.status.idle":"2023-09-28T16:28:54.268393Z","shell.execute_reply.started":"2023-09-28T16:28:54.260381Z","shell.execute_reply":"2023-09-28T16:28:54.267439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-Means Clustering:\n\n\n1. **Model Architecture Explanation:**\n   - K-Means is a centroid-based clustering algorithm.\n   - It starts with randomly initializing K cluster centroids (points in the feature space).\n   - Then, it assigns each data point to the nearest centroid.\n   - After that, it recalculates the centroids as the mean of all points assigned to each cluster.\n   - These two steps (assignment and update) are repeated iteratively until convergence.\n   - The algorithm aims to minimize the sum of squared distances between data points and their respective cluster centroids.\n\n2. **When to Use the Model:**\n   - K-Means is used for clustering data into K distinct groups based on similarity.\n   - It's useful when you have unlabeled data and want to discover hidden patterns or groupings.\n   - Common applications include customer segmentation, image compression, document clustering, and anomaly detection.\n\n3. **Cost Function and Average Time Complexity:**\n   - The cost function of K-Means is the sum of squared distances between data points and their assigned cluster centroids.\n   - Mathematically, it's expressed as: J = Σ ||xⁱ - μᵢ||², where xⁱ is a data point, μᵢ is the centroid of cluster i, and Σ sums over all data points.\n   - K-Means has an average time complexity of O(t * K * N * d), where:\n     - t is the number of iterations (convergence usually occurs within a small number of iterations).\n     - K is the number of clusters.\n     - N is the number of data points.\n     - d is the number of dimensions (features).\n   - Despite its efficiency, K-Means can struggle with large datasets, high dimensionality, and non-spherical clusters.\n\n4. **Evaluation Metrics:**\n   - There are several metrics to evaluate K-Means clustering results, including:\n     - **Inertia or Within-Cluster Sum of Squares (WCSS):** It measures how tightly grouped the data points are within each cluster. Lower values indicate better clustering.\n     - **Silhouette Score:** This metric quantifies how similar each data point is to its own cluster compared to other clusters. Values range from -1 to 1, where higher values are better.\n     - **Davies-Bouldin Index:** It measures the average similarity ratio of each cluster with the cluster that is most similar to it. Lower values suggest better clustering.\n     - **Calinski-Harabasz Index (Variance Ratio Criterion):** It measures the ratio of between-cluster variance to within-cluster variance. Higher values indicate better separation of clusters.\n\n   The choice of evaluation metric depends on the nature of your data and your specific goals. Typically, a combination of these metrics is used to assess the quality of K-Means clustering.","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\n\n# Specify the path to the image\nimage_path = \"/kaggle/input/credit-risk/MqHvx.png\"\n\n# Display the resized image\"\nImage(image_path, width=800, height=800)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-28T16:28:54.269617Z","iopub.execute_input":"2023-09-28T16:28:54.270620Z","iopub.status.idle":"2023-09-28T16:28:54.287336Z","shell.execute_reply.started":"2023-09-28T16:28:54.270586Z","shell.execute_reply":"2023-09-28T16:28:54.286289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Elbow method to find number of clusters\n\nThe Elbow Method is a heuristic technique used to determine the optimal number of clusters in a dataset for K-Means clustering. It is called the \"Elbow Method\" because the plot of the number of clusters against the within-cluster sum of squares (WCSS) resembles an elbow, and the \"elbow point\" is the point at which the WCSS starts to decrease at a slower rate. Here's a detailed explanation of how the Elbow Method works:\n\n**1. Within-Cluster Sum of Squares (WCSS):**\n   - The WCSS measures the compactness of clusters. It is calculated as the sum of squared distances between each data point in a cluster and the centroid of that cluster. Mathematically, for each cluster `k`, the WCSS is given by:\n     ```\n     WCSS(k) = Σ(distance(data_point_i, centroid_k)^2) for all data points in cluster k\n     ```     \n   - The total WCSS for all clusters is calculated as the sum of WCSS for each cluster.\n\n**2. How the Elbow Method Works:**\n   - The Elbow Method involves running the K-Means algorithm for a range of values of `k` (the number of clusters), typically from 1 to a predefined maximum value.\n   \n   - For each value of `k`, calculate the WCSS.\n   \n   - Plot the number of clusters (`k`) against the corresponding WCSS values. You'll typically see a plot where the WCSS decreases as `k` increases. The Elbow Method helps you identify the point at which this decrease slows down, creating an \"elbow\" shape in the plot.\n\n**3. Choosing the Optimal Number of Clusters:**\n   - The key question is, \"Where is the elbow point in the plot?\" This point indicates the optimal number of clusters.\n   \n   - When you plot `k` vs. WCSS, you'll observe that initially, as `k` increases, WCSS decreases sharply. This is because with more clusters, the data points are closer to their respective centroids. However, beyond a certain point, adding more clusters does not significantly reduce the WCSS, and the rate of decrease slows down.\n   \n   - The elbow point is where the rate of WCSS reduction starts to decrease. It represents a balance between the model's complexity (number of clusters) and its goodness of fit (compactness of clusters). Choosing `k` at the elbow point aims to find a balance between overfitting (too many clusters) and underfitting (too few clusters).\n\n**4. Interpreting the Elbow Point:**\n   - There might not always be a clear, distinct elbow point in the plot. In such cases, the choice of `k` may be somewhat subjective. You can use your domain knowledge or other validation techniques to make the final decision.","metadata":{}},{"cell_type":"markdown","source":"Since the dataset is large, this process takes time so you just need to be patient with it.","metadata":{}},{"cell_type":"code","source":"# Step 3: Identify number of clusters with elbow method\nfrom yellowbrick.cluster import KElbowVisualizer\n\nprint('Elbow Method to determine the number of clusters to be formed:')\nElbow_M = KElbowVisualizer(KMeans(), k=15)\nElbow_M.fit(reduced_data)\nElbow_M.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:28:54.288755Z","iopub.execute_input":"2023-09-28T16:28:54.289400Z","iopub.status.idle":"2023-09-28T16:36:31.365443Z","shell.execute_reply.started":"2023-09-28T16:28:54.289369Z","shell.execute_reply":"2023-09-28T16:36:31.364591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### At k=8 the distortion score to WCSS trade-off is balanced, hence it is a recommended choice.","metadata":{}},{"cell_type":"code","source":"# Step 4: K-Means Clustering\noptimal_clusters = 8  # Replace with your chosen number\nkmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\ncluster_labels = kmeans.fit_predict(reduced_data)\n\n# Add cluster labels to the original dataset\ndata_m['cluster'] = cluster_labels","metadata":{"id":"TvwrCUiMzb2D","execution":{"iopub.status.busy":"2023-09-28T16:36:31.366911Z","iopub.execute_input":"2023-09-28T16:36:31.367678Z","iopub.status.idle":"2023-09-28T16:36:59.479765Z","shell.execute_reply.started":"2023-09-28T16:36:31.367643Z","shell.execute_reply":"2023-09-28T16:36:59.478731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have tried to apply Heirarchial Clustering and DBSCAN to this model too.\n\nDue to the very large size of this dataset, \n- Heirarchial kills the kernel, thus terminating the process.\n- DBSCAN doesn't produce any significant variance in clusters.\n\n**Hence, K-Means is the best option here**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsample_size = 1000  \nsampled_data = data_m.sample(sample_size)\n\n# Define the desired order for the 'grade' variable (sorting)\ngrade_order = sorted(data_m['cluster'].unique())\n\n# Define a custom color palette with colors in increasing order\ncustom_palette = sns.color_palette(\"coolwarm\", len(grade_order))\n\n# Create a scatter plot\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='loan_amnt', y='int_rate', hue='cluster', hue_order=grade_order, \n                data=sampled_data, palette=custom_palette)\n\n# Add labels and title\nplt.xlabel('Loan Amount')\nplt.ylabel('Interest Rate')\nplt.title('K means Interest Rates vs Loan Amount Clusters')\n\n# Show legend\nplt.legend(title='Grades', loc='upper right')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:36:59.481297Z","iopub.execute_input":"2023-09-28T16:36:59.481655Z","iopub.status.idle":"2023-09-28T16:37:00.042015Z","shell.execute_reply.started":"2023-09-28T16:36:59.481623Z","shell.execute_reply":"2023-09-28T16:37:00.040469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Interest Rate Prediction","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Assuming X is your feature matrix and y is the target variable (int_rate)\nX = data_m.drop(columns=['int_rate'])  # Exclude target columns\ny = data_m['int_rate']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # You can adjust the test_size\n\n# Initialize a Random Forest Regressor\nrf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)  # You can adjust n_estimators\n\n# Fit the model to the training data\nrf.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = rf.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R-squared: {r2:.2f}\")","metadata":{"id":"wVIYTmCYzb2H","outputId":"0f42b0b4-b351-41d3-9af2-ecdb8674644f","execution":{"iopub.status.busy":"2023-09-28T16:37:00.043573Z","iopub.execute_input":"2023-09-28T16:37:00.044195Z","iopub.status.idle":"2023-09-28T16:41:49.556036Z","shell.execute_reply.started":"2023-09-28T16:37:00.044161Z","shell.execute_reply":"2023-09-28T16:41:49.554511Z"},"trusted":true},"execution_count":null,"outputs":[]}]}